{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Generic set up"
      ],
      "metadata": {
        "id": "4IrWQ0XaW8PV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lI28mD5QozS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bSCN_J84RGN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "KcYpv4W3RIrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "nmzhwNTcRLA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hello world!"
      ],
      "metadata": {
        "id": "MTTlH3TeRs40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor to hold text\n",
        "hello = tf.constant('Hello world!')\n",
        "\n",
        "# Let's try printing this tensor and see what we get\n",
        "print(hello)\n",
        "\n",
        "# What we see here is both the text that is contained in the constant hello and\n",
        "# some of its properties, its shape and data type."
      ],
      "metadata": {
        "id": "VMrHPH3NRsfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computations"
      ],
      "metadata": {
        "id": "jZzi-WytSKrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two tensors that have a constant value then add them together\n",
        "\n",
        "# Create a constant with value 5\n",
        "x = tf.constant(5.0)\n",
        "# Create a constant with value 15\n",
        "y = tf.constant(15.0)  \n",
        "\n",
        "# Add the two constants together and print the result\n",
        "z = x + y\n",
        "print(z)\n",
        "\n",
        "# Note it's been given a default datatype (float32) that was determined by x and\n",
        "# y, a default name, and has no shape as it is a rank-0 tensor (a scalar). \n",
        "# We could also use the following command if we wanted to explicitly use the \n",
        "# tf.add function, e.g. tf.add(x, y)"
      ],
      "metadata": {
        "id": "kdqwH6HRR4C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run some computations using rank 2 tensors (i.e. matrices)\n",
        "\n",
        "# Create constant tensors\n",
        "x = tf.constant([[1, 2, 3],[4, 5, 6]]) \n",
        "y = tf.constant([[6, 5, 4],[3, 2, 1]])  \n",
        "\n",
        "# Add them together and print the result\n",
        "z = tf.add(x,y)\n",
        "print(z)\n",
        "\n",
        "# Note that this output has been given a shape, as it is a rank 2 tensor and \n",
        "# the dtype has changed to int32 "
      ],
      "metadata": {
        "id": "Nj1vSuZvS4Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants vs Variables\n",
        "\n",
        "We have seen so far that constants allow us to create tensors that have pre-determined values. We now introduce Tensorflow variables that contain values that can change during the course of program execution."
      ],
      "metadata": {
        "id": "Of3jf4z7TS1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create variables\n",
        "x = tf.Variable(2, tf.int16)\n",
        "y = tf.Variable(3, tf.int16)\n",
        "z = tf.Variable(2, tf.int16)  \n",
        " \n",
        "# Perform operations on the variables and print the result\n",
        "xy = tf.add(x, y)\n",
        "xyz = tf.multiply(xy, z)\n",
        "print(xyz)"
      ],
      "metadata": {
        "id": "d6VG-FVDTYaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To update the value of a variable we can use the following:\n",
        "# Check value of x\n",
        "print(x)\n",
        "\n",
        "# Update its value\n",
        "x.assign(3, read_value=False)\n",
        "\n",
        "# Print the new variable\n",
        "print(x)\n",
        "\n",
        "# Note, the docs provide the following description for the read_value parameter\n",
        "# \"if True, will return something which evaluates to the new value of the \n",
        "# variable; if False will return the assign op.\" I'm not 100% certain what that\n",
        "# means yet\n",
        "\n",
        "# Note 2, if you want to add or subtract a value from a tensorflow variable then\n",
        "# you can use the assign_add and assign_sub functions"
      ],
      "metadata": {
        "id": "bedonDkdTwb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow and Numpy\n",
        "\n",
        "The variables defined above have a property named numpy. This is the value that is stored in the tensor that will be used in any standard numpy operation.\n",
        "\n",
        "In many contexts, it's possible to use numpy arrays, standard python variables, and TensorFlow tensors interchangeably."
      ],
      "metadata": {
        "id": "Hzz1N1_aVqUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the TensorFlow variable declaration in our earlier example with \n",
        "# standard python variables.\n",
        "\n",
        "# Create variables\n",
        "x = 2\n",
        "y = 3\n",
        "z = 2\n",
        "  \n",
        "# Perform operations on the variables \n",
        "xy = tf.add(x, y)\n",
        "xyz = tf.multiply(xy, z)\n",
        " \n",
        "# Print the output\n",
        "print(xyz)\n",
        "\n",
        "# Note, when we do this the operation tf.add has taken in normal variables,\n",
        "# converted them to tensors and then performed the operations. We can also do\n",
        "# the same thing with multidimensional numpy arrays instead of scalars."
      ],
      "metadata": {
        "id": "TXQ8nOEnVvei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create some numpy arrays with all the same values\n",
        "x = np.full((3,3),2)\n",
        "y = np.full((3,3),3)\n",
        "z = np.full((3,3),2)\n",
        " \n",
        "# Perform operations on the variables \n",
        "xy = tf.add(x, y)\n",
        "xyz = tf.multiply(xy, z)\n",
        "  \n",
        "# Print the output\n",
        "print(xyz)"
      ],
      "metadata": {
        "id": "blqBFPaQWCkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If we want to specifically access the result as an array in numpy, we can \n",
        "# execute the following,\n",
        "\n",
        "# Store the numpy array in a new variable\n",
        "xyz_np = xyz.numpy()\n",
        " \n",
        "# Print the array\n",
        "print(xyz_np)\n",
        "\n",
        "# Note, if you try and pass inconsistent shapes then tensorflow will return an \n",
        "# error stating that we're trying to perform an opteration on tensors with\n",
        "# incompatible shapes."
      ],
      "metadata": {
        "id": "LRMU-L2PWKwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eager mode vs Graph mode\n",
        "\n",
        "TensorFlow allows you to interact with the library in one of two ways.\n",
        "\n",
        "Using eager mode, it works like a normal imperative programming language. You type commands and they are executed immediately. The results are tensors that can be inspected directly or converted to numpy arrays. This is how we have used TensorFlow in the first examples above.\n",
        "\n",
        "The second way is to use graph mode. Here we tell TensorFlow we want to construct a graph of operations that we will reuse over and over. To do this we have to collect our operations into function and use a function decorator to tell Python this function should be treated differentl"
      ],
      "metadata": {
        "id": "uwExcpYiW31b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If we want to switch to graph mode, we have to tell tensorflow that it should \n",
        "# take the function we have defined and compile it into a graph.\n",
        "\n",
        "# To do this we use a function decorator, tf.function. This is placed directly \n",
        "# above the function declaration.\n",
        "\n",
        "# create the function using the function decorator\n",
        "@tf.function\n",
        "def myfunction(X_in,Y_in):\n",
        "    # some complex tensorflow code we want to repeat with different values\n",
        "    X_in = tf.expand_dims(X_in,-1)\n",
        "    Xs = tf.square(X_in)\n",
        "    Xs = tf.reduce_sum(Xs, axis=-1, keepdims=True)\n",
        "    dist = -2 * tf.matmul(X_in, X_in, transpose_b=True)\n",
        "    dist += Xs + tf.linalg.matrix_transpose(Xs)\n",
        "    K = tf.exp(-dist)\n",
        "    K = K + (tf.eye(tf.shape(K)[0], dtype=tf.float64) * 1e-6)\n",
        "    L = tf.linalg.cholesky(K)\n",
        "    f = tf.matmul(L,Y_in)\n",
        "    # end of the complex code\n",
        "\n",
        "    return f\n",
        " \n",
        "# start the timer\n",
        "start = time.time()\n",
        " \n",
        "# run the code once\n",
        "Y = np.random.normal(size=(n,1))\n",
        "f_function = myfunction(X,Y)\n",
        " \n",
        "# report the time\n",
        "print('the code took ', time.time()-start, ' seconds to run')"
      ],
      "metadata": {
        "id": "4s8YkLtbW5vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through this and measure how long it takes to run\n",
        "\n",
        "start = time.time()\n",
        "for i in range(5000):\n",
        "    Y = np.random.normal(size=(n,1))\n",
        "    f_function = myfunction(X,Y)\n",
        " \n",
        "# report the time\n",
        "print('the loop took ', time.time()-start, ' seconds to run')"
      ],
      "metadata": {
        "id": "AptRrz7AX_nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code takes a while to run the first time but is then more efficient after that. \n",
        "\n",
        "This is because the first time the code runs it has to compile the graph and this takes a bit of extra time. Once its done that it can reuse the same graph and so for the next iterations its faster."
      ],
      "metadata": {
        "id": "SjGCMCPqYKqH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eseBNd0eYIns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}