{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorboard as tb    \n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Convert to float32\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "\n",
    "# Flatten images to vectors of length 784 (28*28)\n",
    "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])\n",
    "\n",
    "# Normalize the pixel intensities to make sure their values are between 0 to 1\n",
    "# by dividing them by 255\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "\n",
    "# Train on only 50000 images and keep 10000 images as validation data.\n",
    "x_validate = x_train[0:10000,:]\n",
    "y_validate = y_train[0:10000]\n",
    "\n",
    "x_train = x_train[10000:,:]\n",
    "y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset parameters\n",
    "num_classes = 10\n",
    "num_features = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of shape [784, 10], the 28*28 image features, and a total number of classes.\n",
    "W = tf.Variable(tf.ones([num_features, num_classes]), name=\"weight\")\n",
    "\n",
    "# Bias of shape [10], the total number of classes.\n",
    "b = tf.Variable(tf.zeros([num_classes]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probability for each class\n",
    "def y_pred(x):\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# Cross-Entropy loss function  \n",
    "@tf.function\n",
    "def loss(x, y):\n",
    "    y_true = tf.one_hot(y, depth=num_classes)\n",
    "    y_pred = y_pred(x)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred), axis=1))\n",
    "\n",
    "# Accuracy metric\n",
    "def accuracy(x, y):\n",
    "    y_prob = y_pred(x)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_prob, 1), tf.cast(y, tf.int64))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)).numpy()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "learning_rate = 0.01\n",
    "training_steps = 1000\n",
    "display_step = 50\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "in user code:\n\n    File \"/var/folders/sz/88ypmmqn0jq157npq4hmjtkh0000gp/T/ipykernel_21188/2306332056.py\", line 9, in loss  *\n        y_pred = y_pred(x)\n\n    UnboundLocalError: local variable 'y_pred' referenced before assignment\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(training_steps):\n\u001b[1;32m      3\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m----> 4\u001b[0m         current_loss \u001b[39m=\u001b[39m loss(x_train, y_train)\n\u001b[1;32m      5\u001b[0m     gradiants \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(current_loss, [W, b])\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(gradiants, [W, b]))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/sz/88ypmmqn0jq157npq4hmjtkh0000gp/T/__autograph_generated_filedyugr1of.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__loss\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m y_true \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mone_hot, (ag__\u001b[39m.\u001b[39mld(y),), \u001b[39mdict\u001b[39m(depth\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(num_classes)), fscope)\n\u001b[0;32m---> 11\u001b[0m y_pred \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(y_pred), (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: in user code:\n\n    File \"/var/folders/sz/88ypmmqn0jq157npq4hmjtkh0000gp/T/ipykernel_21188/2306332056.py\", line 9, in loss  *\n        y_pred = y_pred(x)\n\n    UnboundLocalError: local variable 'y_pred' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "# Optimization process\n",
    "for i in range(training_steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss(x_train, y_train)\n",
    "    gradiants = tape.gradient(current_loss, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradiants, [W, b]))\n",
    "    if i % display_step == 0:\n",
    "        print(\"i: %i, loss: %f\" % (i, current_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.08000183105469"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
